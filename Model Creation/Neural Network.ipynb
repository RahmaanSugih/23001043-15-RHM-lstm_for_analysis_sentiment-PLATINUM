{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4d5e3d",
   "metadata": {},
   "source": [
    "# Menyiapkan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c490e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31916be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_preprocess.tsv.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e318f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115d3a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>makanan beragam , harga makanan di food stall ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "1  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "2  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "3  duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
       "4  makanan beragam , harga makanan di food stall ...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7d5c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10999, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba466e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d38fdce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e41f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f7de0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387717ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stopword = pd.read_csv('stopword.csv', encoding = 'latin1')\n",
    "df_alay = pd.read_csv('kamus_alay1.csv',  encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fb5707",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adalah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adapun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stopword\n",
       "0      ada\n",
       "1   adalah\n",
       "2   adanya\n",
       "3   adapun\n",
       "4     agak"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stopword.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cddfe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kata_lama</th>\n",
       "      <th>Kata_baru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anakjakartaasikasik</td>\n",
       "      <td>anak jakarta asyik asyik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Kata_lama                 Kata_baru\n",
       "0  anakjakartaasikasik  anak jakarta asyik asyik\n",
       "1         pakcikdahtua         pak cik sudah tua\n",
       "2       pakcikmudalagi         pak cik muda lagi\n",
       "3          t3tapjokowi              tetap jokowi\n",
       "4                   3x                 tiga kali"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a754834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46d71763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleansing\n",
    "def preprocess_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Hapus emotikon dan karakter khusus\n",
    "    text = re.sub(r'[^\\w\\d\\s]', '', text)\n",
    "\n",
    "    # mengganti spasi yang berlebihan\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Menghapus kata dan huruf yang bergabung\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Mengganti kata yang berulang\n",
    "    text = re.sub(r'\\b(\\w+)\\1\\b', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "#removing stopwords\n",
    "stopwords = df_stopword['stopword'].tolist()\n",
    "def remove_stopwords(text):\n",
    "    list_stopwords = text.split()\n",
    "    return ' '.join([text for text in list_stopwords if text not in stopwords])\n",
    "\n",
    "#normalization\n",
    "kamus_alay = dict(zip(df_alay['Kata_lama'], df_alay['Kata_baru']))\n",
    "def normalize(text):\n",
    "    for word in kamus_alay:\n",
    "        return ' '.join([kamus_alay[word] if word in kamus_alay else word for word in text.split(' ')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab4eb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_text(text):\n",
    "    text = preprocess_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = normalize(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd83c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(cleansing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "925367ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5703535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "def stem_text(tokens):\n",
    "    return stemmer.stem(tokens)\n",
    "\n",
    "df['text_clean'] = df['text_clean'].apply(stem_text)\n",
    "df.to_csv('data_clean.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d59d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus beri hujjah partai wilah sua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis jalan sumatra bandung nyaman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia unboxing paket barang bagus tet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>aduh mahasiswa sombong kasih kartu kuning ajar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>makanan beragam , harga makanan di food stall ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>makan agam harga makan food stall kasir suasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10927</th>\n",
       "      <td>f - demokrat dorong upaya kemandirian energi n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>f demokrat dorong upaya mandiri energi nasional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10928</th>\n",
       "      <td>tidak bosan</td>\n",
       "      <td>positive</td>\n",
       "      <td>bosan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10929</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>positive</td>\n",
       "      <td>enak masakan kepiting senang pilih kepiting se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10930</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>pagi pagi tol pasteur macet parah jengkel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10931</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>positive</td>\n",
       "      <td>belanja yogyakarta riau junction kali lihat fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10932 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  \\\n",
       "0      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "1      lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "2      betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "3      duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "4      makanan beragam , harga makanan di food stall ...  positive   \n",
       "...                                                  ...       ...   \n",
       "10927  f - demokrat dorong upaya kemandirian energi n...   neutral   \n",
       "10928                                        tidak bosan  positive   \n",
       "10929  enak rasa masakan nya apalagi kepiting yang me...  positive   \n",
       "10930  pagi pagi di tol pasteur sudah macet parah , b...  negative   \n",
       "10931  meskipun sering belanja ke yogya di riau junct...  positive   \n",
       "\n",
       "                                              text_clean  \n",
       "0      mohon ulama lurus beri hujjah partai wilah sua...  \n",
       "1      lokasi strategis jalan sumatra bandung nyaman ...  \n",
       "2      betapa bahagia unboxing paket barang bagus tet...  \n",
       "3      aduh mahasiswa sombong kasih kartu kuning ajar...  \n",
       "4      makan agam harga makan food stall kasir suasan...  \n",
       "...                                                  ...  \n",
       "10927    f demokrat dorong upaya mandiri energi nasional  \n",
       "10928                                              bosan  \n",
       "10929  enak masakan kepiting senang pilih kepiting se...  \n",
       "10930          pagi pagi tol pasteur macet parah jengkel  \n",
       "10931  belanja yogyakarta riau junction kali lihat fo...  \n",
       "\n",
       "[10932 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_clean.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "611193e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 6377, Neu: 1138, Neg: 3405\n",
      "Total data: 10920\n"
     ]
    }
   ],
   "source": [
    "neg = df.loc[df['label'] == 'negative'].text.tolist()\n",
    "neu = df.loc[df['label'] == 'neutral'].text.tolist()\n",
    "pos = df.loc[df['label'] == 'positive'].text.tolist()\n",
    "\n",
    "neg_label = df.loc[df['label'] == 'negative'].label.tolist()\n",
    "neu_label = df.loc[df['label'] == 'neutral'].label.tolist()\n",
    "pos_label = df.loc[df['label'] == 'positive'].label.tolist()\n",
    "\n",
    "total_data = pos + neu + neg\n",
    "labels = pos_label + neu_label + neg_label\n",
    "\n",
    "print('Pos: %s, Neu: %s, Neg: %s' % (len(pos), len(neu), len(neg)))\n",
    "print('Total data: %s' % len(total_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3de757",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4929bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b629e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction selesai\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(cleaned_data)\n",
    "\n",
    "X = count_vect.transform(cleaned_data)\n",
    "print (\"Feature Extraction selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1584439b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10920, 17238)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3b46211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(count_vect, open(\"feature.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d345ab",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b808d5c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classes = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1951061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57e29c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ed4d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print (\"Training selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be031bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c80908fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.79      0.78       683\n",
      "     neutral       0.76      0.65      0.70       246\n",
      "    positive       0.88      0.89      0.88      1255\n",
      "\n",
      "    accuracy                           0.83      2184\n",
      "   macro avg       0.80      0.78      0.79      2184\n",
      "weighted avg       0.83      0.83      0.83      2184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test = model.predict(X_test)\n",
    "\n",
    "print (\"Testing selesai\")\n",
    "print(classification_report(y_test, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276429c2",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a1a39b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:\n",
      "\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "original_text =  '''\n",
    "aku pintar\n",
    "'''\n",
    "\n",
    "text = count_vect.transform([cleansing_text(original_text)])\n",
    "\n",
    "result = model.predict(text)[0]\n",
    "print(\"Sentiment:\")\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6f74f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:\n",
      "\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "original_text =  '''\n",
    "kamu ga bodoh\n",
    "'''\n",
    "\n",
    "text = count_vect.transform([cleansing_text(original_text)])\n",
    "\n",
    "result = model.predict(text)[0]\n",
    "print(\"Sentiment:\")\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f5b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
